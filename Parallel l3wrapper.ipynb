{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/andrea/Documents/Politecnico/tirocinio/src/../\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from os.path import join\n",
    "\n",
    "import arff\n",
    "from snapshottest import TestCase\n",
    "\n",
    "from src import DEFAULT_DIR\n",
    "from src.XPLAIN_explainer import XPLAIN_explainer\n",
    "from src.dataset import Dataset\n",
    "\n",
    "\n",
    "def load_arff(f) -> Dataset:\n",
    "    a = arff.load(f)\n",
    "    dataset = Dataset(a['data'], a['attributes'])\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def import_dataset_arff(f, explain_indices,random_explain_dataset: bool):\n",
    "    dataset = load_arff(f)\n",
    "\n",
    "    dataset_len = len(dataset)\n",
    "    train_indices = list(range(dataset_len))\n",
    "\n",
    "    if random_explain_dataset:\n",
    "        random.seed(1)\n",
    "        # small dataset\n",
    "        MAX_SAMPLE_COUNT = 100\n",
    "        if dataset_len < (2 * MAX_SAMPLE_COUNT):\n",
    "            samples = int(0.2 * dataset_len)\n",
    "        else:\n",
    "            samples = MAX_SAMPLE_COUNT\n",
    "\n",
    "        # Randomly pick some instances to remove from the training dataset and use in the\n",
    "        # explain dataset\n",
    "        explain_indices = list(random.sample(train_indices, samples))\n",
    "    for i in explain_indices:\n",
    "        train_indices.remove(i)\n",
    "\n",
    "    train_dataset = Dataset.from_indices(train_indices, dataset)\n",
    "    explain_dataset = Dataset.from_indices(explain_indices, dataset)\n",
    "\n",
    "    return train_dataset, explain_dataset, [str(i) for i in explain_indices]\n",
    "\n",
    "\n",
    "def import_datasets_arff(f, f_explain, explain_indices,random_explain_dataset: bool):\n",
    "    train_dataset = load_arff(f)\n",
    "    explain_dataset = load_arff(f_explain)\n",
    "\n",
    "    len_explain_dataset = len(explain_dataset)\n",
    "\n",
    "    if random_explain_dataset:\n",
    "        random.seed(7)\n",
    "        explain_indices = list(random.sample(range(len_explain_dataset), 300))\n",
    "        explain_dataset = Dataset.from_indices(explain_indices, explain_dataset)\n",
    "\n",
    "    return train_dataset, explain_dataset, [str(i) for i in explain_indices]\n",
    "\n",
    "\n",
    "def get_classifier(classifier_name: str):\n",
    "    if classifier_name == \"sklearn_nb\":\n",
    "        from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "        skl_clf = MultinomialNB()\n",
    "\n",
    "        return skl_clf\n",
    "\n",
    "    elif classifier_name == \"sklearn_rf\":\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        from sklearn.pipeline import make_pipeline\n",
    "        from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "        pipe = make_pipeline(OneHotEncoder(), RandomForestClassifier(random_state=42))\n",
    "        skl_clf = pipe\n",
    "\n",
    "        return skl_clf\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Classifier not available\")\n",
    "\n",
    "\n",
    "def get_explanation(dataset_name: str, classifier_name: str):\n",
    "    explain_dataset_indices = []\n",
    "    if dataset_name in [join(DEFAULT_DIR, \"datasets/adult_d.arff\"),\n",
    "                        join(DEFAULT_DIR, \"datasets/compas-scores-two-years_d.arff\")]:\n",
    "        with open(dataset_name) as f, open(dataset_name[:-5] + \"_explain.arff\") as f_explain:\n",
    "            train_dataset, explain_dataset, explain_indices = import_datasets_arff(f, f_explain,\n",
    "                                                                                   explain_dataset_indices,\n",
    "                                                                                   True)\n",
    "    else:\n",
    "        with open(dataset_name) as f:\n",
    "            train_dataset, explain_dataset, explain_indices = import_dataset_arff(\n",
    "                f, explain_dataset_indices, True)\n",
    "\n",
    "    clf = get_classifier(classifier_name).fit(train_dataset.X_numpy(),\n",
    "                                              train_dataset.Y_numpy())\n",
    "    explainer = XPLAIN_explainer(clf, train_dataset)\n",
    "\n",
    "    instance = explain_dataset.get_decoded(0)\n",
    "\n",
    "    cc = explain_dataset.class_column_name()\n",
    "    target_class_index = instance[cc]\n",
    "\n",
    "    return explainer.explain_instance(explain_dataset[0], target_class_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l3wrapper(instance_ix, train):\n",
    "    from l3wrapper.l3wrapper import L3Classifier\n",
    "    \n",
    "    clf = L3Classifier(min_sup=0.01, min_conf=0.50)\n",
    "    clf.fit(train.X_decoded(),\n",
    "            train.Y_decoded(),\n",
    "            column_names=train.X_decoded().columns.to_list(),\n",
    "           remove_files=False)\n",
    "    \n",
    "    decoded_instance = train.inverse_transform_instance(train[instance_ix])\n",
    "    encoded_rules = clf.lvl1_rules_\n",
    "\n",
    "    def decode_rule(r, clf):\n",
    "        r_class = clf._class_dict[r.class_id]\n",
    "        r_attr_ixs_and_values = sorted([clf._item_id_to_item[i] for i in r.item_ids])\n",
    "        r_attrs_and_values = [(clf._column_id_to_name[c], v) for c, v in r_attr_ixs_and_values]\n",
    "        return {'body': r_attrs_and_values, 'class': r_class}\n",
    "\n",
    "    rules = []\n",
    "    \n",
    "    for r in encoded_rules:\n",
    "        # For each of its attributes and values\n",
    "        for a,v in decode_rule(r, clf)['body']:\n",
    "            # If rule uses an attribute's value different from the instance's\n",
    "            if decoded_instance[a] != v:\n",
    "                # Exit the inner loop, not entering the else clause, therefore not adding the rule\n",
    "                break\n",
    "        # https://docs.python.org/3/tutorial/controlflow.html#break-and-continue-statements-and-else-clauses-on-loops\n",
    "        else:\n",
    "            # If the inner loop has completed normally without break-ing, then all of the rule's\n",
    "            # attribute values are in the instance as well, so we will use this rule\n",
    "\n",
    "            # Get the instance attribute index from the rule's item_ids\n",
    "            di = decoded_instance.index\n",
    "            \n",
    "            # Class matching\n",
    "            if decode_rule(r, clf)['class'] == decoded_instance.iloc[-1]:\n",
    "                rules.append(list(sorted([di.get_loc(a) + 1 for a, v in decode_rule(r, clf)['body']])))\n",
    "    \n",
    "    return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join(DEFAULT_DIR, \"datasets/zoo.arff\")) as zoo_f:\n",
    "    zoo_train, zoo_explain, zoo_explain_indices = import_dataset_arff(zoo_f, [], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l3wrapper(44, zoo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "def f(i):\n",
    "    return i,l3wrapper(i, zoo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, [[2, 3, 4, 8, 9, 10, 11]])\n",
      "(1, [[2, 3, 4, 8, 9, 10, 11]])\n",
      "(2, [[1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14]])\n",
      "(3, [[2, 3, 4, 8, 9, 10, 11]])\n",
      "(4, [[2, 3, 4, 8, 9, 10, 11]])\n",
      "(5, [[2, 3, 4, 8, 9, 10, 11]])\n",
      "(6, [[1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14]])\n",
      "(7, [[2, 3, 4, 8, 9, 10, 11]])\n",
      "(8, [[2, 3, 4, 8, 9, 10, 11]])\n",
      "(9, [[1, 2, 3, 4, 8, 9, 10, 11, 12, 13, 14]])\n",
      "(10, [[1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15], [1, 2, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16]])\n",
      "(11, [[1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15]])\n",
      "(12, [[1, 2, 3, 4, 8, 9, 10, 11, 12, 13, 14]])\n",
      "(13, [[1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14]])\n",
      "(14, [[2, 3, 4, 8, 9, 10, 11]])\n",
      "(15, [[1, 2, 3, 4, 8, 9, 10, 11, 12, 13, 14]])\n",
      "(16, [[1, 2, 3, 4, 8, 9, 10, 11, 12, 13, 14]])\n",
      "(17, [[2, 3, 4, 8, 9, 10, 11]])\n",
      "(18, [[1, 2, 3, 4, 8, 9, 10, 11, 12, 13, 14]])\n",
      "(19, [[2, 3, 4, 6, 8, 9, 10, 12, 13, 14, 16]])\n",
      "(20, [[1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16]])\n",
      "(21, [[2, 3, 4, 8, 9, 10, 11]])\n",
      "(22, [[2, 3, 4, 8, 9, 10, 11]])\n",
      "(23, [[2, 3, 4, 8, 9, 10, 11]])\n",
      "(24, [[2, 3, 4, 6, 8, 9, 10, 12, 13, 14, 16]])\n",
      "(25, [[2, 3, 4, 8, 9, 10, 11]])\n",
      "(26, [[1, 2, 3, 4, 8, 9, 10, 11, 12, 13, 14]])\n",
      "(27, [[1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14]])\n",
      "(28, [[2, 3, 4, 8, 9, 10, 11]])\n",
      "(29, [[2, 3, 4, 8, 9, 10, 11]])\n",
      "(30, [[1, 2, 3, 4, 8, 9, 10, 11, 12, 13, 14]])\n",
      "(31, [[1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14]])\n",
      "(32, [[2, 3, 4, 6, 8, 9, 10, 12, 13, 14, 16]])\n",
      "(33, [[2, 3, 4, 6, 8, 9, 10, 12, 13, 14, 16]])\n",
      "(34, [[1, 2, 3, 4, 8, 9, 10, 11, 12, 13, 14]])\n",
      "(35, [[2, 3, 4, 6, 8, 9, 10, 12, 13, 14, 16]])\n",
      "(36, [[1, 2, 3, 4, 8, 9, 10, 11, 12, 13, 14]])\n",
      "(37, [[2, 3, 4, 8, 9, 10, 11]])\n",
      "(38, [[2, 3, 4, 8, 9, 10, 11]])\n",
      "(39, [[1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15]])\n",
      "CPU times: user 1.24 s, sys: 244 ms, total: 1.48 s\n",
      "Wall time: 5.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(40):\n",
    "    print(f(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, [[2, 3, 4, 8, 9, 10, 11]])\n",
      "(1, [[2, 3, 4, 8, 9, 10, 11]])\n",
      "(2, [[1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14]])\n",
      "(3, [[2, 3, 4, 8, 9, 10, 11]])\n",
      "(4, [[2, 3, 4, 8, 9, 10, 11]])\n",
      "(5, [[2, 3, 4, 8, 9, 10, 11]])\n",
      "(6, [[1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14]])\n",
      "(7, [[2, 3, 4, 8, 9, 10, 11]])\n",
      "(8, [[2, 3, 4, 8, 9, 10, 11]])\n",
      "(9, [[1, 2, 3, 4, 8, 9, 10, 11, 12, 13, 14]])\n",
      "(10, [[1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15], [1, 2, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16]])\n",
      "(11, [[1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15]])\n",
      "(12, [[1, 2, 3, 4, 8, 9, 10, 11, 12, 13, 14]])\n",
      "(13, [[1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14]])\n",
      "(14, [[2, 3, 4, 8, 9, 10, 11]])\n",
      "(15, [[1, 2, 3, 4, 8, 9, 10, 11, 12, 13, 14]])\n",
      "(16, [[1, 2, 3, 4, 8, 9, 10, 11, 12, 13, 14]])\n",
      "(17, [[2, 3, 4, 8, 9, 10, 11]])\n",
      "(18, [[1, 2, 3, 4, 8, 9, 10, 11, 12, 13, 14]])\n",
      "(19, [[2, 3, 4, 6, 8, 9, 10, 12, 13, 14, 16]])\n",
      "(20, [[1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16]])\n",
      "(21, [[2, 3, 4, 8, 9, 10, 11]])\n",
      "(22, [[2, 3, 4, 8, 9, 10, 11]])\n",
      "(23, [[2, 3, 4, 8, 9, 10, 11]])\n",
      "(24, [[2, 3, 4, 6, 8, 9, 10, 12, 13, 14, 16]])\n",
      "(25, [[2, 3, 4, 8, 9, 10, 11]])\n",
      "(26, [[1, 2, 3, 4, 8, 9, 10, 11, 12, 13, 14]])\n",
      "(27, [[1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14]])\n",
      "(28, [[2, 3, 4, 8, 9, 10, 11]])\n",
      "(29, [[2, 3, 4, 8, 9, 10, 11]])\n",
      "(30, [[1, 2, 3, 4, 8, 9, 10, 11, 12, 13, 14]])\n",
      "(31, [[1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14]])\n",
      "(32, [[2, 3, 4, 6, 8, 9, 10, 12, 13, 14, 16]])\n",
      "(33, [[2, 3, 4, 6, 8, 9, 10, 12, 13, 14, 16]])\n",
      "(34, [[1, 2, 3, 4, 8, 9, 10, 11, 12, 13, 14]])\n",
      "(35, [[2, 3, 4, 6, 8, 9, 10, 12, 13, 14, 16]])\n",
      "(36, [[1, 2, 3, 4, 8, 9, 10, 11, 12, 13, 14]])\n",
      "(37, [[2, 3, 4, 8, 9, 10, 11]])\n",
      "(38, [[2, 3, 4, 8, 9, 10, 11]])\n",
      "(39, [[1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15]])\n",
      "CPU times: user 27.8 ms, sys: 3.93 ms, total: 31.7 ms\n",
      "Wall time: 1.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with Pool(4) as p:\n",
    "    [print(r) for r in p.map(f, range(min(len(zoo_train), 40)))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "299px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 752.85,
   "position": {
    "height": "783.85px",
    "left": "1531px",
    "right": "20px",
    "top": "117px",
    "width": "374px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
